[BASEMODEL]
batch_size              = 64 # 64 
precision               = "16-mixed"
loss_function			= "L1Loss" #"L1Loss" #""MSELoss", "WeightedMSELoss", "GradientWeightedMSELoss"

[ADVANCEDMODEL]
drop_rate               = 0.05 #0.03
gan_mode			    = "vanilla" # options: "wgangp", "vanilla", "lsgan"
inference               = false
max_epochs              = 50
random_seed             = 1991
activation			    = "LeakyReLU" # default LeakyReLU
name				    = "BasicUnetPlusPlus" # 'BasicUnetPlusPlus', 'Pix2Pix'
unet_features			= [32, 32, 64, 128, 256, 32] #[64, 128, 256, 512, 1024, 128]
#unet_features           = [64, 128, 256, 512, 1024, 128]

[AUGMENTATIONS]
median_kernel_size      = [3,3]#[5,5]

[AUGMENTATIONS_KORNIA] # those are transforms that will be done on the training set only.
RandomGaussianNoise     = '{"p": 0.5, "std": 0.04}'
RandomSharpness         = '{"p": 0.8, "sharpness": 0.8}'
RandomMedianBlur        = '{"p": 0.5, "kernel_size": (5, 5)}'

[CHECKPOINT]
mode                    = "min"
monitor                 = "val_loss_epoch"
logger_folder			= "lightning_logs/UnetPlusPlus/test_nomedian_28aug_LossOnProfile/"


[DATA]
# All the datasets are here: ["alderson_front", "alderson_front_highE", "alderson_lat", "empty", "empty_highE", "gammex", "LV", "SR_132", "SR_213", "SR_321", "SR_456", "SR_645"]
views 			        = ["Top", "Lateral"]
base_folder             = '/home/dgs1/data/P2C/corrected_cropped/'
# First test which doesnt look like its learning much:
#train_datasets			= ["alderson_front", "alderson_front_highE", "empty", "LV", "SR_132", "SR_213", "SR_321", "SR_456"]
#val_datasets			= ["gammex", "SR_645", "alderson_lat", "empty_highE"]
# The below is saved here - /home/dgs1/Software/Proton2Carbon/lightning_logs/UnetPlusPlus/different_data_save_config/BasicUnetPlusPlus/version_2/checkpoints/BasicUnetPlusPlus-epoch=34_val_loss=0.02.ckpt (trained on 2 gpus)
#train_datasets			= ['LV', 'empty', 'alderson_front', 'alderson_lat', 'SR_645', 'SR_456', 'SR_213', 'SR_321', 'gammex']
#val_datasets			= ['empty_highE', 'alderson_front_highE', 'SR_132']
#test_datasets			= [] 
# This one below is saved here - /home/dgs1/Software/Proton2Carbon/lightning_logs/UnetPlusPlus/different_data_save_config/BasicUnetPlusPlus/version_4/checkpoints/BasicUnetPlusPlus-epoch=21_val_loss=0.02.ckpt (trained on 2 gpus)
#train_datasets			= ['LV', 'empty', 'alderson_front', 'empty_highE', 'alderson_front_highE', 'SR_456', 'SR_213', 'SR_321', 'SR_132']
#val_datasets			= ['gammex', 'SR_645', 'alderson_lat']
#test_datasets			= [] 
# This one is running (job # 945) - I wanna see how the Gammex performs when we have different training datasets.
#train_datasets			= ['SR_645', 'empty', 'alderson_front', 'empty_highE', 'alderson_front_highE', 'SR_456', 'alderson_lat', 'SR_321', 'SR_132']
#val_datasets			= ['gammex', 'LV', 'SR_213']
#test_datasets			= [] 
# This one is running (job # 947) - I wanna see what happens when we test on Alderson, not trained on any.
train_datasets			= ['LV', 'gammex', 'SR_645', 'empty_highE', 'empty', 'SR_456', 'SR_213', 'SR_321', 'SR_132']
val_datasets			= ['alderson_lat', 'alderson_front', 'alderson_front_highE']
test_datasets			= [] 

[OPTIMIZER]
algorithm	            = 'Adam'
eps                     = 1e-7
lr                      = 1e-4
#lr_G                    = 2e-4#8e-5#3e-4
#lr_D        		    = 1e-4#1e-4
beta1_adam				= 0.9
#beta1_adam			    = 0.5
beta2_adam			    = 0.999

[REGULARIZATION]
label_smoothing         = 0.03
optimizer_weight_decay  = 1e-5 #1e-5
#l1_Weight_g			    = 100#100

[SCHEDULER]
#lin_gamma           = 0.8
#lin_step_size       = 6
type                = 'CosineAnnealingLR' #'stepLR'
